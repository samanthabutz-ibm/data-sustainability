{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fde386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammadnauman/opt/anaconda3/envs/ESG_MVP_IBM/lib/python3.8/site-packages/snowflake/connector/options.py:96: UserWarning: You have an incompatible version of 'pyarrow' installed (10.0.1), please install a version that adheres to: 'pyarrow<8.1.0,>=8.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 0)\n",
      "[Row(CURRENT_WAREHOUSE()='WH_ESG_SUSTAINABILITY', CURRENT_DATABASE()='DL_ESG_DEV', CURRENT_SCHEMA()='CUSTOMER')]\n"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark.types import *\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from snowflake.snowpark.functions import udf\n",
    "%matplotlib inline\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import snowflake.connector\n",
    "# to save the trained scaler class\n",
    "import joblib\n",
    "\n",
    "#Snowflake connection info\n",
    "# from config import snowflake_conn_prop\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "snowflake_conn_prop = {\n",
    "   \"account\": \"se58322-fsesg\",\n",
    "   \"user\": \"Muhammad Nauman\",\n",
    "   \"password\": \"Muhammad23\",\n",
    "   \"role\": \"DEVELOPER\",\n",
    "   \"database\": \"DL_ESG_DEV\",\n",
    "   \"schema\": \"CUSTOMER\",\n",
    "   \"warehouse\": \"WH_ESG_SUSTAINABILITY\",\n",
    "}\n",
    "\n",
    "from snowflake.snowpark import version\n",
    "print(version.VERSION)\n",
    "\n",
    "\n",
    "connection_paramter = snowflake.connector.connect(account = \"se58322-fsesg\",\n",
    "                        user=\"Muhammad Nauman\",\n",
    "                        password=\"Muhammad23\",\n",
    "                        role=\"DEVELOPER\",\n",
    "                        warehouse=\"WH_ESG_SUSTAINABILITY\",\n",
    "                        ocsp_fail_open=False)\n",
    "\n",
    "session = Session.builder.configs(snowflake_conn_prop).create()\n",
    "print(session.sql('select current_warehouse(), current_database(), current_schema()').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47263b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nr/vyfq21gx5pn1p0025dclx97c0000gn/T/ipykernel_10390/213873629.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(qry, connection_paramter)\n",
      "/var/folders/nr/vyfq21gx5pn1p0025dclx97c0000gn/T/ipykernel_10390/213873629.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_port = pd.read_sql(qry, connection_paramter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40000, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "# qry = \"SELECT * FROM DL_ESG_DEV.CUSTOMER.CUSTOMER\"\n",
    "qry = 'SELECT * FROM DL_ESG_DEV.ESG.TRIAL_SCO_ESG_262'\n",
    "\n",
    "df = pd.read_sql(qry, connection_paramter)\n",
    "\n",
    "esg_df = df.copy()\n",
    "# articles_df = articles_df[articles_df['eventType'] == 'CONTENT SHARED']\n",
    "esg_df.head(5)\n",
    "\n",
    "\n",
    "qry = 'SELECT * FROM DL_ESG_DEV.CUSTOMER.PORTFOLIO'\n",
    "\n",
    "df_port = pd.read_sql(qry, connection_paramter)\n",
    "\n",
    "port_df = df_port.copy()\n",
    "port_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52fb008",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_df\n",
    "esg_df = esg_df.rename({'ticker': 'TICKER'}, axis=1)  # new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d875087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = port_df.merge(esg_df, on='TICKER', how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "077e8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = merged_df.head().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "109530b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[[\"esg\", \"OWNED\"]] = merged_df[[\"esg\", \"OWNED\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0beedb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_ID</th>\n",
       "      <th>P_ID</th>\n",
       "      <th>TICKER</th>\n",
       "      <th>BUY_DATE</th>\n",
       "      <th>BUY_VALUE</th>\n",
       "      <th>SHARES_</th>\n",
       "      <th>CURRENCY</th>\n",
       "      <th>OWNED</th>\n",
       "      <th>ADVISOR_ID</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>dom_country_iso</th>\n",
       "      <th>dom_region</th>\n",
       "      <th>exch_country_iso</th>\n",
       "      <th>exch_region</th>\n",
       "      <th>economic_sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>esg</th>\n",
       "      <th>esg_e</th>\n",
       "      <th>esg_s</th>\n",
       "      <th>esg_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2983a8d1-d25d-4508-84b2-eb0be516e5be</td>\n",
       "      <td>98b8c46d-386e-491e-aee6-f95386f66b99</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>1457222400000</td>\n",
       "      <td>291</td>\n",
       "      <td>14</td>\n",
       "      <td>JPY</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>f520e014-1243-43b7-a179-0f3ac88d2663</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>Electronic Technology</td>\n",
       "      <td>Electronic Equipment/Instruments</td>\n",
       "      <td>56.92</td>\n",
       "      <td>47.17</td>\n",
       "      <td>55.37</td>\n",
       "      <td>62.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dca12977-8107-4642-9e2f-f933849e97a0</td>\n",
       "      <td>12453938-522e-4763-9fca-ee51218a4927</td>\n",
       "      <td>0R2I</td>\n",
       "      <td>1627948800000</td>\n",
       "      <td>278</td>\n",
       "      <td>13</td>\n",
       "      <td>USD</td>\n",
       "      <td>16.433333</td>\n",
       "      <td>b2171a34-7c1d-4000-9d47-c63f46e54248</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Consumer Non-Durables</td>\n",
       "      <td>Apparel/Footwear</td>\n",
       "      <td>43.25</td>\n",
       "      <td>37.66</td>\n",
       "      <td>48.09</td>\n",
       "      <td>43.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f413f981-27ec-4245-bf6b-de3bbe36b3aa</td>\n",
       "      <td>61a5c2b5-ad1e-4d57-9fa7-7b4653362868</td>\n",
       "      <td>0JR2</td>\n",
       "      <td>1604793600000</td>\n",
       "      <td>219</td>\n",
       "      <td>10</td>\n",
       "      <td>JPY</td>\n",
       "      <td>25.266667</td>\n",
       "      <td>0e44ad22-1db9-45c8-a61c-fedfca18e8e9</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Industrial Services</td>\n",
       "      <td>Oil &amp; Gas Pipelines</td>\n",
       "      <td>51.92</td>\n",
       "      <td>51.40</td>\n",
       "      <td>49.20</td>\n",
       "      <td>53.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4293c697-ed6e-476d-9608-bba687c91fca</td>\n",
       "      <td>4dc5d3b7-1019-4505-92d0-f2c0b0ce9e6c</td>\n",
       "      <td>0I6Q</td>\n",
       "      <td>1648339200000</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "      <td>USD</td>\n",
       "      <td>8.633333</td>\n",
       "      <td>e97bf078-8afd-4d2f-b4d6-30c239e22359</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Electric Utilities</td>\n",
       "      <td>54.80</td>\n",
       "      <td>65.91</td>\n",
       "      <td>56.83</td>\n",
       "      <td>45.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4484c558-d61b-4e0f-8559-3b1db2d9ad84</td>\n",
       "      <td>377dedb9-2a7a-45d5-a689-a89dc8ccb88e</td>\n",
       "      <td>CTAS</td>\n",
       "      <td>1653264000000</td>\n",
       "      <td>211</td>\n",
       "      <td>10</td>\n",
       "      <td>EUR</td>\n",
       "      <td>6.766667</td>\n",
       "      <td>6975916f-0f6a-405d-9f48-087b89b63b4b</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>Other Consumer Services</td>\n",
       "      <td>51.04</td>\n",
       "      <td>57.29</td>\n",
       "      <td>58.64</td>\n",
       "      <td>40.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   R_ID                                  P_ID  \\\n",
       "0  2983a8d1-d25d-4508-84b2-eb0be516e5be  98b8c46d-386e-491e-aee6-f95386f66b99   \n",
       "1  dca12977-8107-4642-9e2f-f933849e97a0  12453938-522e-4763-9fca-ee51218a4927   \n",
       "2  f413f981-27ec-4245-bf6b-de3bbe36b3aa  61a5c2b5-ad1e-4d57-9fa7-7b4653362868   \n",
       "3  4293c697-ed6e-476d-9608-bba687c91fca  4dc5d3b7-1019-4505-92d0-f2c0b0ce9e6c   \n",
       "4  4484c558-d61b-4e0f-8559-3b1db2d9ad84  377dedb9-2a7a-45d5-a689-a89dc8ccb88e   \n",
       "\n",
       "  TICKER       BUY_DATE BUY_VALUE SHARES_ CURRENCY      OWNED  \\\n",
       "0   TRMB  1457222400000       291      14      JPY  81.333333   \n",
       "1   0R2I  1627948800000       278      13      USD  16.433333   \n",
       "2   0JR2  1604793600000       219      10      JPY  25.266667   \n",
       "3   0I6Q  1648339200000       126       6      USD   8.633333   \n",
       "4   CTAS  1653264000000       211      10      EUR   6.766667   \n",
       "\n",
       "                             ADVISOR_ID        date  ... dom_country_iso  \\\n",
       "0  f520e014-1243-43b7-a179-0f3ac88d2663  2018-01-01  ...             USA   \n",
       "1  b2171a34-7c1d-4000-9d47-c63f46e54248  2018-01-01  ...             USA   \n",
       "2  0e44ad22-1db9-45c8-a61c-fedfca18e8e9  2018-01-01  ...             USA   \n",
       "3  e97bf078-8afd-4d2f-b4d6-30c239e22359  2018-01-01  ...             USA   \n",
       "4  6975916f-0f6a-405d-9f48-087b89b63b4b  2018-01-01  ...             USA   \n",
       "\n",
       "      dom_region exch_country_iso    exch_region        economic_sector  \\\n",
       "0  North America              USA  North America  Electronic Technology   \n",
       "1  North America              GBR         Europe  Consumer Non-Durables   \n",
       "2  North America              GBR         Europe    Industrial Services   \n",
       "3  North America              GBR         Europe              Utilities   \n",
       "4  North America              USA  North America      Consumer Services   \n",
       "\n",
       "                           industry    esg  esg_e  esg_s  esg_g  \n",
       "0  Electronic Equipment/Instruments  56.92  47.17  55.37  62.78  \n",
       "1                  Apparel/Footwear  43.25  37.66  48.09  43.98  \n",
       "2               Oil & Gas Pipelines  51.92  51.40  49.20  53.59  \n",
       "3                Electric Utilities  54.80  65.91  56.83  45.37  \n",
       "4           Other Consumer Services  51.04  57.29  58.64  40.30  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d91032f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4629.493333\n",
       "1     710.741667\n",
       "2    1311.845333\n",
       "3     473.106667\n",
       "4     345.370667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.apply(lambda row: row['OWNED'] * row['esg'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e85c663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['eventStrength'] = merged_df.apply(lambda row: row['OWNED'] * row['esg'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "475bc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c7360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aefb96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users: 2000\n",
      "# users with at least 5 interactions: 2000\n"
     ]
    }
   ],
   "source": [
    "users_interactions_count_df = interactions_df.groupby(['P_ID', 'TICKER']).size().groupby('P_ID').size()\n",
    "print('# users: %d' % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['P_ID']]\n",
    "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a909df37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of interactions: 40000\n",
      "# of interactions from users with at least 5 interactions: 40000\n"
     ]
    }
   ],
   "source": [
    "print('# of interactions: %d' % len(interactions_df))\n",
    "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \n",
    "               how = 'right',\n",
    "               left_on = 'P_ID',\n",
    "               right_on = 'P_ID')\n",
    "print('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c88194ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique user/item interactions: 39182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_ID</th>\n",
       "      <th>TICKER</th>\n",
       "      <th>eventStrength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000da565-ff4d-4d73-bbc1-7905b4582cc1</td>\n",
       "      <td>0HCZ</td>\n",
       "      <td>12.555691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000da565-ff4d-4d73-bbc1-7905b4582cc1</td>\n",
       "      <td>0HEU</td>\n",
       "      <td>12.017101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000da565-ff4d-4d73-bbc1-7905b4582cc1</td>\n",
       "      <td>0HF7</td>\n",
       "      <td>10.841074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000da565-ff4d-4d73-bbc1-7905b4582cc1</td>\n",
       "      <td>0HVP</td>\n",
       "      <td>10.126485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000da565-ff4d-4d73-bbc1-7905b4582cc1</td>\n",
       "      <td>0HYE</td>\n",
       "      <td>10.269183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000da565-ff4d-4d73-bbc1-7905b4582cc1</td>\n",
       "      <td>0I0J</td>\n",
       "      <td>12.777215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000da565-ff4d-4d73-bbc1-7905b4582cc1</td>\n",
       "      <td>0IBC</td>\n",
       "      <td>12.404377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000da565-ff4d-4d73-bbc1-7905b4582cc1</td>\n",
       "      <td>0ITV</td>\n",
       "      <td>11.392832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000da565-ff4d-4d73-bbc1-7905b4582cc1</td>\n",
       "      <td>0J1R</td>\n",
       "      <td>11.127675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000da565-ff4d-4d73-bbc1-7905b4582cc1</td>\n",
       "      <td>0JVI</td>\n",
       "      <td>12.247632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   P_ID TICKER  eventStrength\n",
       "0  000da565-ff4d-4d73-bbc1-7905b4582cc1   0HCZ      12.555691\n",
       "1  000da565-ff4d-4d73-bbc1-7905b4582cc1   0HEU      12.017101\n",
       "2  000da565-ff4d-4d73-bbc1-7905b4582cc1   0HF7      10.841074\n",
       "3  000da565-ff4d-4d73-bbc1-7905b4582cc1   0HVP      10.126485\n",
       "4  000da565-ff4d-4d73-bbc1-7905b4582cc1   0HYE      10.269183\n",
       "5  000da565-ff4d-4d73-bbc1-7905b4582cc1   0I0J      12.777215\n",
       "6  000da565-ff4d-4d73-bbc1-7905b4582cc1   0IBC      12.404377\n",
       "7  000da565-ff4d-4d73-bbc1-7905b4582cc1   0ITV      11.392832\n",
       "8  000da565-ff4d-4d73-bbc1-7905b4582cc1   0J1R      11.127675\n",
       "9  000da565-ff4d-4d73-bbc1-7905b4582cc1   0JVI      12.247632"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def smooth_user_preference(x):\n",
    "    # print(x)\n",
    "    ## Need to see if this is ok for negatie values\n",
    "    return math.log(1+abs(x), 2)\n",
    "    \n",
    "interactions_full_df = interactions_from_selected_users_df \\\n",
    "                    .groupby(['P_ID', 'TICKER'])['eventStrength'].sum() \\\n",
    "                    .apply(smooth_user_preference).reset_index()\n",
    "print('# of unique user/item interactions: %d' % len(interactions_full_df))\n",
    "interactions_full_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6aa69493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# interactions on Train set: 31345\n",
      "# interactions on Test set: 7837\n"
     ]
    }
   ],
   "source": [
    "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
    "                                   stratify=interactions_full_df['P_ID'], \n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)\n",
    "\n",
    "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
    "print('# interactions on Test set: %d' % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "977e44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing by personId to speed up the searches during evaluation\n",
    "interactions_full_indexed_df = interactions_full_df.set_index('P_ID')\n",
    "interactions_train_indexed_df = interactions_train_df.set_index('P_ID')\n",
    "interactions_test_indexed_df = interactions_test_df.set_index('P_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4603d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_interacted(person_id, interactions_df):\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    interacted_items = interactions_df.loc[person_id]['TICKER']\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])\n",
    "\n",
    "#Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "class ModelEvaluator:\n",
    "\n",
    "\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n",
    "        all_items = set(articles_df['TICKER'])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \n",
    "            try:\n",
    "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "            except:\n",
    "                index = -1\n",
    "            hit = int(index in range(0, topn))\n",
    "            return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        #Getting the items in test set\n",
    "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
    "        if type(interacted_values_testset['TICKER']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['TICKER'])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([int(interacted_values_testset['TICKER'])])  \n",
    "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "        #Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(person_id, \n",
    "                                               items_to_ignore=get_items_interacted(person_id, \n",
    "                                                                                    interactions_train_indexed_df), \n",
    "                                               topn=10000000000)\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        #For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            #Getting a random sample (100) items the user has not interacted \n",
    "            #(to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n",
    "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
    "                                                                          seed=item_id%(2**32))\n",
    "\n",
    "            #Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['TICKER'].isin(items_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['TICKER'].values\n",
    "            #Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        #when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                          'hits@10_count':hits_at_10_count, \n",
    "                          'interacted_count': interacted_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        #print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(list(interactions_test_indexed_df.index.unique().values)):\n",
    "            #if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)  \n",
    "            person_metrics['_P_ID'] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "                            .sort_values('interacted_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50a8c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluator = ModelEvaluator() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "223658d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICKER</th>\n",
       "      <th>eventStrength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0RR8</td>\n",
       "      <td>1158.008986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0IUX</td>\n",
       "      <td>1143.003893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0LSZ</td>\n",
       "      <td>1140.894932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TFX</td>\n",
       "      <td>1116.716173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CTLT</td>\n",
       "      <td>1111.681094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0HMZ</td>\n",
       "      <td>1109.759937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0L5A</td>\n",
       "      <td>1102.917265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMZ</td>\n",
       "      <td>1098.819110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0KOD</td>\n",
       "      <td>1095.308612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0R13</td>\n",
       "      <td>1086.696896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TICKER  eventStrength\n",
       "0   0RR8    1158.008986\n",
       "1   0IUX    1143.003893\n",
       "2   0LSZ    1140.894932\n",
       "3    TFX    1116.716173\n",
       "4   CTLT    1111.681094\n",
       "5   0HMZ    1109.759937\n",
       "6   0L5A    1102.917265\n",
       "7    AMZ    1098.819110\n",
       "8   0KOD    1095.308612\n",
       "9   0R13    1086.696896"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computes the most popular items\n",
    "item_popularity_df = interactions_full_df.groupby('TICKER')['eventStrength'].sum().sort_values(ascending=False).reset_index()\n",
    "item_popularity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ebde7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Popularity'\n",
    "    \n",
    "    def __init__(self, popularity_df, items_df=None):\n",
    "        self.popularity_df = popularity_df\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        # Recommend the more popular items that the user hasn't seen yet.\n",
    "        recommendations_df = self.popularity_df[~self.popularity_df['TICKER'].isin(items_to_ignore)] \\\n",
    "                               .sort_values('eventStrength', ascending = False) \\\n",
    "                               .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "# \texch_region\teconomic_sector\tindustry\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'TICKER', \n",
    "                                                          right_on = 'TICKER')[['eventStrength', 'TICKER', 'esg', 'exch_region', 'economic_sector', 'industry']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "popularity_model = PopularityRecommender(item_popularity_df, esg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f65f6dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Popularity recommendation model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluating Popularity recommendation model...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m pop_global_metrics, pop_detailed_results_df \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopularity_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGlobal metrics:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m pop_global_metrics)\n\u001b[1;32m      4\u001b[0m pop_detailed_results_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[42], line 84\u001b[0m, in \u001b[0;36mModelEvaluator.evaluate_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     80\u001b[0m people_metrics \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, person_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mlist\u001b[39m(interactions_test_indexed_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mvalues)):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m#if idx % 100 == 0 and idx > 0:\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m#    print('%d users processed' % idx)\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     person_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model_for_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperson_id\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     85\u001b[0m     person_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_P_ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m person_id\n\u001b[1;32m     86\u001b[0m     people_metrics\u001b[38;5;241m.\u001b[39mappend(person_metrics)\n",
      "Cell \u001b[0;32mIn[42], line 52\u001b[0m, in \u001b[0;36mModelEvaluator.evaluate_model_for_user\u001b[0;34m(self, model, person_id)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#For each item the user has interacted in test set\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item_id \u001b[38;5;129;01min\u001b[39;00m person_interacted_items_testset:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m#Getting a random sample (100) items the user has not interacted \u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m#(to represent items that are assumed to be no relevant to the user)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     non_interacted_items_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_not_interacted_items_sample(person_id, \n\u001b[1;32m     51\u001b[0m                                                                   sample_size\u001b[38;5;241m=\u001b[39mEVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n\u001b[0;32m---> 52\u001b[0m                                                                   seed\u001b[38;5;241m=\u001b[39m\u001b[43mitem_id\u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m#Combining the current interacted item with the 100 random items\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     items_to_filter_recs \u001b[38;5;241m=\u001b[39m non_interacted_items_sample\u001b[38;5;241m.\u001b[39munion(\u001b[38;5;28mset\u001b[39m([item_id]))\n",
      "\u001b[0;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    }
   ],
   "source": [
    "print('Evaluating Popularity recommendation model...')\n",
    "pop_global_metrics, pop_detailed_results_df = model_evaluator.evaluate_model(popularity_model)\n",
    "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
    "pop_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f14e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6a95c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e9a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd69df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83e50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a145b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf1c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_data.py\n",
    "\n",
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0005f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same data that was plotted for similarity earlier\n",
    "# with one new user \"E\" who has rated only movie 1\n",
    "ratings_dict = {\n",
    "    \"item\": [1, 2, 1, 2, 1, 2, 1, 2, 1],\n",
    "    \"user\": ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D', 'E'],\n",
    "    \"rating\": [1, 2, 2, 4, 2.5, 4, 4.5, 5, 3],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Loads Pandas dataframe\n",
    "data = Dataset.load_from_df(df[[\"user\", \"item\", \"rating\"]], reader)\n",
    "# Loads the builtin Movielens-100k data\n",
    "movielens = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6969211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommender.py\n",
    "\n",
    "from surprise import KNNWithMeans\n",
    "\n",
    "# To use item-based cosine similarity\n",
    "sim_options = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": False,  # Compute  similarities between items\n",
    "}\n",
    "algo = KNNWithMeans(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5917aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('ESG_MVP_IBM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa0fc5040d70973588a06ccbf176cea31104864950066c489d3162ac1fac7967"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
